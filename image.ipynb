{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import models\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport seaborn as sns\nimport pandas as pd\nfrom collections import OrderedDict\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ===============================================\n# 1. ГЛОБАЛЬНЫЕ НАСТРОЙКИ (гиперпараметры)\n# ===============================================\nDATA_DIR       = 'path/to/your/dataset'          # Основная папка с данными\nTRAIN_DIR      = os.path.join(DATA_DIR, 'train')  # Папка с тренировочными изображениями\nVAL_DIR        = os.path.join(DATA_DIR, 'val')    # Папка с валидационными изображениями\nTEST_DIR       = os.path.join(DATA_DIR, 'test')   # Папка с тестовыми изображениями (может быть без меток или с ними)\n\nNUM_CLASSES    = 10                    # <<< ИЗМЕНИТЕ НА СВОЁ КОЛИЧЕСТВО КЛАССОВ\nBATCH_SIZE     = 64\nNUM_EPOCHS     = 50\nLEARNING_RATE  = 0.001\nWEIGHT_DECAY   = 1e-4                  # L2-регуляризация\nDEVICE         = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nPRINT_FREQ     = 100                   # Как часто выводить loss во время эпохи\nSEED           = 42                    # Для воспроизводимости\n\n# Фиксируем случайность — важный момент для экспериментов!\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\nnp.random.seed(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nprint(f\"Используем устройство: {DEVICE}\")\nprint(f\"Количество классов: {NUM_CLASSES}\")\n\n# ===============================================\n# 2. АУГМЕНТАЦИИ И ЗАГРУЗКА ДАННЫХ\n# ===============================================\n\n# Тренировочные аугментации — делаем данные разнообразнее, чтобы модель лучше обобщала\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Случайный кроп с изменением масштаба\n    transforms.RandomHorizontalFlip(p=0.5),              # Горизонтальный поворот\n    transforms.RandomRotation(15),                       # Поворот до ±15°\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomGrayscale(p=0.1),                   # Иногда делаем ч/б\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],      # Статистика ImageNet\n                         std =[0.229, 0.224, 0.225]),\n])\n\n# Валидация и тест — только детерминированные трансформации (без случайности)\ntransform_val_test = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std =[0.229, 0.224, 0.225]),\n])\n\n# Загружаем датасеты через ImageFolder (структура: папка_класса/изображения)\ntrain_dataset = ImageFolder(TRAIN_DIR, transform=transform_train)\nval_dataset   = ImageFolder(VAL_DIR,   transform=transform_val_test)\n\n# Тестовый датасет может быть:\n#   а) с метками (тогда тоже ImageFolder)\n#   б) без меток — тогда используем torchvision.datasets.ImageFolder с кастомным loader'ом (ниже показано оба варианта)\ntest_dataset = ImageFolder(TEST_DIR, transform=transform_val_test)  # если есть метки\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n                          num_workers=8, pin_memory=True, drop_last=False)\nval_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,\n                          num_workers=8, pin_memory=True)\ntest_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False,\n                          num_workers=8, pin_memory=True)\n\n# Названия классов (очень полезно для отчётов)\nclass_names = train_dataset.classes\nclass_to_idx = train_dataset.class_to_idx\nprint(f\"Классы ({len(class_names)}): {class_names}\")\nprint(f\"class_to_idx: {class_to_idx}\")\n\n# ===============================================\n# 3. СОЗДАНИЕ МОДЕЛИ (Transfer Learning)\n# ===============================================\n\n# Выбираем любую предобученную модель. Здесь — ResNet50 (можно заменить на EfficientNet, Swin и т.д.)\nbase_model = models.resnet50(pretrained=True)  # weights=models.ResNet50_Weights.IMAGENET1K_V2 в новых версиях\n\n# --- Вариант A: Замораживаем все слои кроме последнего (быстрее, меньше переобучения) ---\nfor param in base_model.parameters():\n    param.requires_grad = False\n\n# Меняем финальный слой под наши классы\nnum_features = base_model.fc.in_features\nbase_model.fc = nn.Linear(num_features, NUM_CLASSES)\n\n# Если хотите дообучать всю сеть (fine-tuning) — раскомментируйте:\n# for param in base_model.parameters():\n#     param.requires_grad = True\n\nmodel = base_model.to(DEVICE)\n\n# ===============================================\n# 4. ФУНКЦИЯ ПОТЕРЬ, ОПТИМИЗАТОР, ПЛАНИРОВЩИК\n# ===============================================\ncriterion = nn.CrossEntropyLoss()  # Для многоклассовой классификации\n\n# Оптимизатор только по тем параметрам, которые обучаются\noptimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n                        lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# Планировщик обучения — косинусный отжиг (очень эффективен)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n\n# ===============================================\n# 5. ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ ОБУЧЕНИЯ И ВАЛИДАЦИИ\n# ===============================================\n\ndef train_one_epoch(epoch_idx):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    pbar = tqdm(train_loader, desc=f'Epoch {epoch_idx+1:02d}/{NUM_EPOCHS} [TRAIN]')\n    for batch_idx, (images, targets) in enumerate(pbar):\n        images = images.to(DEVICE, non_blocking=True)\n        targets = targets.to(DEVICE, non_blocking=True)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        # Обновляем прогресс-бар\n        if batch_idx % PRINT_FREQ == 0 or batch_idx == len(train_loader)-1:\n            pbar.set_postfix({\n                'loss': running_loss / (batch_idx + 1),\n                'acc' : 100. * correct / total,\n                'lr'  : optimizer.param_groups[0]['lr']\n            })\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc  = 100. * correct / total\n    return epoch_loss, epoch_acc\n\n\n@torch.no_grad()\ndef validate(epoch_idx):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n\n    pbar = tqdm(val_loader, desc=f'Epoch {epoch_idx+1:02d}/{NUM_EPOCHS} [VAL  ]', leave=False)\n    for images, targets in pbar:\n        images = images.to(DEVICE, non_blocking=True)\n        targets = targets.to(DEVICE, non_blocking=True)\n\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(targets.cpu().numpy())\n\n    epoch_loss = running_loss / len(val_loader)\n    epoch_acc  = 100. * correct / total\n    print(f\"VALIDATION → Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n    return epoch_loss, epoch_acc, np.array(all_preds), np.array(all_labels)\n\n\n# ===============================================\n# 6. ОСНОВНОЙ ЦИКЛ ОБУЧЕНИЯ\n# ===============================================\nbest_val_acc = 0.0\nhistory = {\n    'train_loss': [], 'train_acc': [],\n    'val_loss'  : [], 'val_acc'  : []\n}\n\nprint(\"\\n=== НАЧИНАЕМ ОБУЧЕНИЕ ===\\n\")\nfor epoch in range(NUM_EPOCHS):\n    train_loss, train_acc = train_one_epoch(epoch)\n    val_loss,   val_acc, _, _ = validate(epoch)\n    \n    scheduler.step()  # обновляем LR\n\n    # Сохраняем историю\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n\n    # Сохраняем лучшую модель по валидационной точности\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_acc': val_acc\n        }, 'best_model.pth')\n        print(f\"  → НОВАЯ ЛУЧШАЯ МОДЕЛЬ! Val Acc: {best_val_acc:.2f}%\\n\")\n\nprint(f\"\\nОБУЧЕНИЕ ЗАВЕРШЕНО. Лучшая валидационная точность: {best_val_acc:.2f}%\\n\")\n\n# ===============================================\n# 7. ФИНАЛЬНАЯ ОЦЕНКА НА ВАЛИДАЦИИ + МЕТРИКИ\n# ===============================================\nprint(\"=== ЗАГРУЖАЕМ ЛУЧШУЮ МОДЕЛЬ ДЛЯ ФИНАЛЬНОЙ ОЦЕНКИ ===\")\ncheckpoint = torch.load('best_model.pth', map_location=DEVICE)\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\n_, _, val_preds, val_labels = validate(0)  # просто прогоняем ещё раз\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"CLASSIFICATION REPORT (VALIDATION)\")\nprint(\"=\"*50)\nprint(classification_report(val_labels, val_preds, target_names=class_names, digits=4))\n\n# Confusion Matrix\ncm = confusion_matrix(val_labels, val_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix (Validation)')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()\n\n# ===============================================\n# 8. ПРЕДСКАЗАНИЕ НА ТЕСТОВОМ НАБОРЕ (TEST SET)\n# ===============================================\n@torch.no_grad()\ndef predict_test(loader, save_csv=True):\n    model.eval()\n    all_filenames = []\n    all_preds = []\n    all_probs = []\n    all_labels = [] if hasattr(loader.dataset, 'targets') else None\n\n    print(\"\\n=== ПРЕДСКАЗАНИЕ НА ТЕСТОВОМ НАБОРЕ ===\")\n    pbar = tqdm(loader, desc=\"Test inference\")\n    \n    for images, targets_or_paths in pbar:\n        # ImageFolder возвращает targets, но если вы используете кастомный Dataset — можно передавать пути\n        if isinstance(targets_or_paths, tuple):  # если у вас кастомный loader с путями\n            images, paths = images\n        else:\n            paths = None\n\n        images = images.to(DEVICE, non_blocking=True)\n\n        outputs = model(images)\n        probabilities = torch.softmax(outputs, dim=1)\n        _, predicted = outputs.max(1)\n\n        # Сохраняем имена файлов (если доступны)\n        if paths is not None:\n            all_filenames.extend(paths)\n        elif hasattr(loader.dataset, 'imgs'):\n            # ImageFolder хранит пути в .imgs\n            batch_start = len(all_filenames)\n            batch_paths = [loader.dataset.imgs[i][0] for i in range(batch_start, batch_start + images.size(0))]\n            all_filenames.extend([os.path.basename(p) for p in batch_paths])\n\n        all_preds.extend(predicted.cpu().numpy())\n        all_probs.extend(probabilities.cpu().numpy())\n        if all_labels is not None:\n            all_labels.extend(targets_or_paths.cpu().numpy() if torch.is_tensor(targets_or_paths) else targets_or_paths)\n\n    # Преобразуем предсказания в названия классов\n    pred_labels = [class_names[idx] for idx in all_preds]\n    prob_df = pd.DataFrame(all_probs, columns=[f'prob_{c}' for c in class_names])\n\n    results_df = pd.DataFrame({\n        'filename': all_filenames if all_filenames else [f'img_{i}' for i in range(len(all_preds))],\n        'predicted_class_id': all_preds,\n        'predicted_class': pred_labels,\n        'confidence': prob_df.max(axis=1).values  # максимальная вероятность\n    })\n    results_df = pd.concat([results_df, prob_df], axis=1)\n\n    if save_csv:\n        results_df.to_csv('test_predictions.csv', index=False)\n        print(f\"Предсказания сохранены в 'test_predictions.csv' ({len(results_df)} записей)\")\n\n    # Если в тесте есть метки — выводим точность\n    if all_labels is not None and len(all_labels) > 0:\n        test_acc = accuracy_score(all_labels, all_preds) * 100\n        print(f\"Test Accuracy: {test_acc:.2f}%\")\n\n    return results_df\n\n# Запускаем предсказание\ntest_results_df = predict_test(test_loader, save_csv=True)\n\n# Показываем первые 10 строк результата\nprint(\"\\nПервые 10 предсказаний:\")\nprint(test_results_df.head(10))\n\n# ===============================================\n# 9. ГРАФИКИ ОБУЧЕНИЯ\n# ===============================================\nplt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history['train_loss'], label='Train Loss')\nplt.plot(history['val_loss'],   label='Val Loss')\nplt.title('Loss during training')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.plot(history['train_acc'], label='Train Acc')\nplt.plot(history['val_acc'],   label='Val Acc')\nplt.title('Accuracy during training')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}