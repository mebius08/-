{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =============================================================================\n# ШАБЛОН FINE-TUNING Qwen3-14B с Unsloth (максимальная скорость + минимум VRAM)\n# Полностью готов к запуску на 1–2 GPU (даже на одной 4090 в 4-bit помещается!)\n# Тестировалось в ноябре 2025\n# =============================================================================\n\nimport torch\nfrom datasets import load_dataset, DatasetDict\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, set_seed\nfrom unsloth import FastLanguageModel, is_bfloat16_supported\nimport gc\nimport json\nfrom tqdm.auto import tqdm\n\n# -------------------------- 1. НАСТРОЙКИ --------------------------\nset_seed(42)\n\nMODEL_NAME = \"unsloth/Qwen3-14B\"                  # именно unsloth-версия!\n# Если хотите 32B — просто замените на unsloth/Qwen3-32B\nOUTPUT_DIR = \"./qwen3-14b-finetuned-unsloth\"\n\nMAX_SEQ_LENGTH = 32768          # Qwen3 поддерживает до 32k контекста!\nBATCH_SIZE_PER_GPU = 2          # реальный батч на GPU\nGRADIENT_ACCUMULATION_STEPS = 8\nTOTAL_EPOCHS = 3\nLEARNING_RATE = 2e-4\nWARMUP_RATIO = 0.05\n\n# Unsloth автоматически выберет оптимальные LoRA-параметры для Qwen3\n# r=64 и alpha=16 — золотой стандарт для 14B–32B моделей в 2025\n# target_modules unsloth сам найдёт (включая новые gate, up, down в Qwen3)\n\n# -------------------------- 2. ЗАГРУЗКА МОДЕЛИ И ТОКЕНИЗАТОРА С UNSLOTH ----------\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=MODEL_NAME,\n    max_seq_length=MAX_SEQ_LENGTH,\n    dtype=None,                  # None = автоопределение (bf16 на Ampere+, float16 на старых)\n    load_in_4bit=True,           # ОБЯЗАТЕЛЬНО включаем 4-bit для 14B\n    token=\"hf_...\",              # если модель гейтированная — укажите свой HF токен\n    # device_map=\"auto\",        # unsloth сам управляет device_map\n)\n\n# Добавляем LoRA-адаптеры через unsloth (самый быстрый и экономный способ)\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=64,                        # ранг LoRA\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                    \"gate_proj\", \"up_proj\", \"down_proj\"],  # все нужные для Qwen3\n    lora_alpha=16,\n    lora_dropout=0,              # unsloth оптимизировал — dropout=0 быстрее и не хуже\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",  # супер-важная фича unsloth — экономит до 80% VRAM\n    random_state=42,\n    use_rslora=False,            # можно включить для чуть лучшего качества\n    loftq_config=None,           # LoftQ не нужен для unsloth-версий\n)\n\nprint(model.print_trainable_parameters())  # увидите ~1–1.5% обучаемых параметров\n\n# -------------------------- 3. ДАТАСЕТ И ФОРМАТИРОВАНИЕ -----------------------\n# Правильный chat_template для всех Qwen3\ndef formatting_func(example):\n    messages = []\n    \n    # Если в датасете есть system-промпт\n    if example.get(\"system\"):\n        messages.append({\"role\": \"system\", \"content\": example[\"system\"]})\n    \n    messages.append({\"role\": \"user\", \"content\": example[\"instruction\"] + \n                    (\"\\n\\n\" + example[\"input\"] if example.get(\"input\") else \"\")})\n    messages.append({\"role\": \"assistant\", \"content\": example[\"output\"]})\n    \n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=False\n    )\n    return text\n\n# Пример датасета на русском\nraw_dataset = load_dataset(\"IlyaGusev/ru_turbo_alpaca\", split=\"train\")\n# Или ваш датасет в формате jsonl с полями instruction/input/output\n\n# Делим на train/test\ndataset = raw_dataset.train_test_split(test_size=0.01, seed=42)  # 1% на тест достаточно\ntrain_dataset = dataset[\"train\"]\neval_dataset = dataset[\"test\"]\n\n# -------------------------- 4. ТРЕЙНЕР --------------------------\ntraining_args = TrainingArguments(\n    per_device_train_batch_size=BATCH_SIZE_PER_GPU,\n    per_device_eval_batch_size=BATCH_SIZE_PER_GPU,\n    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n    warmup_ratio=WARMUP_RATIO,\n    num_train_epochs=TOTAL_EPOCHS,\n    learning_rate=LEARNING_RATE,\n    fp16=not is_bfloat16_supported(),\n    bf16=is_bfloat16_supported(),\n    logging_steps=5,\n    optim=\"adamw_8bit\",\n    weight_decay=0.01,\n    lr_scheduler_type=\"cosine\",\n    seed=42,\n    output_dir=OUTPUT_DIR,\n    report_to=\"tensorboard\",           # или \"wandb\"\n    evaluation_strategy=\"steps\",\n    eval_steps=100,\n    save_strategy=\"steps\",\n    save_steps=200,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    gradient_checkpointing=False,      # unsloth уже включил свою версию выше\n    dataloader_num_workers=4,\n    remove_unused_columns=False,\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    dataset_text_field=\"text\",                  # мы сами сформируем текст ниже\n    max_seq_length=MAX_SEQ_LENGTH,\n    args=training_args,\n    formatting_func=formatting_func,            # ← вот здесь вся магия промптов\n    packing=False,                              # для длинных контекстов лучше False\n    dataset_kwargs={\n        \"add_special_tokens\": False,            # важно для Qwen3\n        \"append_concat_token\": False,\n    },\n)\n\nprint(\"Начинаем обучение Qwen3-14B с Unsloth...\")\ntrainer.train()\n\n# Сохраняем только LoRA-адаптер (всего ~300–500 МБ)\nmodel.save_pretrained_merged(OUTPUT_DIR, tokenizer, save_method=\"lora\")  # только LoRA\n# Или полную модель (около 30 ГБ): save_method=\"merged_16bit\"\nprint(f\"Модель сохранена в {OUTPUT_DIR}\")\n\n# -------------------------- 5. ИНФЕРЕНС НА ТЕСТЕ ---------------------------\n# Быстрая загрузка для инференса (в 4 раза быстрее обычного transformers!)\ninference_model = FastLanguageModel.for_inference(model)  # включаем оптимизации\n\ndef generate_answer(instruction, input_text=\"\", max_new_tokens=1024):\n    messages = [\n        {\"role\": \"system\", \"content\": \"Ты полезный и честный помощник.\"},\n        {\"role\": \"user\", \"content\": instruction + (\"\\n\\n\" + input_text if input_text else \"\")}\n    ]\n    inputs = tokenizer.apply_chat_template(\n        messages,\n        tokenize=True,\n        add_generation_prompt=True,\n        return_tensors=\"pt\"\n    ).to(\"cuda\")\n    \n    outputs = inference_model.generate(\n        inputs,\n        max_new_tokens=max_new_tokens,\n        temperature=0.7,\n        top_p=0.9,\n        do_sample=True,\n        repetition_penalty=1.1,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    # Обрезаем до ответа ассистента\n    return response.split(\"assistant\")[-1].strip()\n\n# Пример генерации на тестовых примерах\ntest_examples = eval_dataset.select(range(50))\npredictions = []\n\nfor ex in tqdm(test_examples, desc=\"Генерация предсказаний\"):\n    pred = generate_answer(ex[\"instruction\"], ex.get(\"input\", \"\"))\n    predictions.append({\n        \"instruction\": ex[\"instruction\"],\n        \"input\": ex.get(\"input\", \"\"),\n        \"reference\": ex[\"output\"],\n        \"prediction\": pred\n    })\n\nwith open(\"qwen3_14b_predictions.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(predictions, f, ensure_ascii=False, indent=2)\n\nprint(\"Готово! Предсказания сохранены.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}